<!DOCTYPE HTML><html lang="zh-CN"><head><meta charset="utf-8"><meta name="keywords" content="Scrapy网络爬虫, HTML, CSS, JavaScript, JQuery, React, Vue.js"><meta name="description" content="千城墨染的个人博客"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="renderer" content="webkit|ie-stand|ie-comp"><meta name="mobile-web-app-capable" content="yes"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><title>Scrapy网络爬虫 | 千城墨染</title><link rel="icon" type="image/png" href="/favicon.png"><link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.css"><link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css"><link rel="stylesheet" type="text/css" href="/libs/aos/aos.css"><link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css"><link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css"><link rel="stylesheet" type="text/css" href="/css/matery.css"><link rel="stylesheet" type="text/css" href="/css/my.css"><link rel="stylesheet" type="text/css" href="/css/loading.css"><script src="/libs/jquery/jquery.min.js"></script><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="千城墨染" type="application/atom+xml"><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css">
<link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><script>$(document).ready(function(){document.body.style.overflow="auto",document.getElementById("loading-box").classList.add("loaded")})</script><header class="navbar-fixed"><nav id="headNav" class="bg-color nav-transparent"><div id="navContainer" class="nav-wrapper container"><div class="brand-logo"><a href="/" class="waves-effect waves-light"><img src="/medias/logo.png" class="logo-img" alt="LOGO"> <span class="logo-span">千城墨染</span></a></div><a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a><ul class="right nav-menu"><li class="hide-on-med-and-down nav-item"><a href="/" class="waves-effect waves-light"><i class="fas fa-home" style="zoom:.6"></i> <span>首页</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/tags" class="waves-effect waves-light"><i class="fas fa-tags" style="zoom:.6"></i> <span>标签</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/categories" class="waves-effect waves-light"><i class="fas fa-bookmark" style="zoom:.6"></i> <span>分类</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/archives" class="waves-effect waves-light"><i class="fas fa-archive" style="zoom:.6"></i> <span>归档</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/about" class="waves-effect waves-light"><i class="fas fa-user-circle" style="zoom:.6"></i> <span>关于</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/contact" class="waves-effect waves-light"><i class="fas fa-comments" style="zoom:.6"></i> <span>留言板</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/friends" class="waves-effect waves-light"><i class="fas fa-address-book" style="zoom:.6"></i> <span>友情链接</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/navigate" class="waves-effect waves-light"><i class="fas fa-location-arrow" style="zoom:.6"></i> <span>导航</span></a></li><li><a href="#searchModal" class="modal-trigger waves-effect waves-light"><i id="searchIcon" class="fas fa-search" title="搜索" style="zoom:.85"></i></a></li></ul><div id="mobile-nav" class="side-nav sidenav"><div class="mobile-head bg-color"><img src="/medias/logo.png" class="logo-img circle responsive-img"><div class="logo-name">千城墨染</div><div class="logo-desc">千城墨染的个人博客</div></div><ul class="menu-list mobile-menu-list"><li class="m-nav-item"><a href="/" class="waves-effect waves-light"><i class="fa-fw fas fa-home"></i> 首页</a></li><li class="m-nav-item"><a href="/tags" class="waves-effect waves-light"><i class="fa-fw fas fa-tags"></i> 标签</a></li><li class="m-nav-item"><a href="/categories" class="waves-effect waves-light"><i class="fa-fw fas fa-bookmark"></i> 分类</a></li><li class="m-nav-item"><a href="/archives" class="waves-effect waves-light"><i class="fa-fw fas fa-archive"></i> 归档</a></li><li class="m-nav-item"><a href="/about" class="waves-effect waves-light"><i class="fa-fw fas fa-user-circle"></i> 关于</a></li><li class="m-nav-item"><a href="/contact" class="waves-effect waves-light"><i class="fa-fw fas fa-comments"></i> 留言板</a></li><li class="m-nav-item"><a href="/friends" class="waves-effect waves-light"><i class="fa-fw fas fa-address-book"></i> 友情链接</a></li><li class="m-nav-item"><a href="/navigate" class="waves-effect waves-light"><i class="fa-fw fas fa-location-arrow"></i> 导航</a></li></ul></div></div></nav></header><script src="/libs/cryptojs/crypto-js.min.js"></script><script>(function() {
        let pwd = '';
        if (pwd && pwd.length > 0) {
            if (pwd !== CryptoJS.SHA256(prompt('请输入访问本文章的密码？')).toString(CryptoJS.enc.Hex)) {
                alert('密码错误，将返回主页！');
                location.href = '/';
            }
        }
    })();</script><div class="bg-cover pd-header post-cover" style="background-image:url(/medias/featureimages/6.jpg)"><div class="container" style="right:0;left:0"><div class="row"><div class="col s12 m12 l12"><div class="brand"><h1 class="description center-align post-title">Scrapy网络爬虫</h1></div></div></div></div></div><main class="post-container content"><link rel="stylesheet" href="/libs/tocbot/tocbot.css"><style>#articleContent h1::before,#articleContent h2::before,#articleContent h3::before,#articleContent h4::before,#articleContent h5::before,#articleContent h6::before{display:block;content:" ";height:100px;margin-top:-100px;visibility:hidden}#articleContent :focus{outline:0}.toc-fixed{position:fixed;top:64px}.toc-widget{width:345px;padding-left:20px;background-color:rgb(255,255,255,.7);border-radius:10px;box-shadow:0 10px 35px 2px rgba(0,0,0,.15),0 5px 15px rgba(0,0,0,.07),0 2px 5px -5px rgba(0,0,0,.1)!important}.toc-widget .toc-title{padding:35px 0 15px 17px;font-size:1.5rem;font-weight:700;line-height:1.5rem}.toc-widget ol{padding:0;list-style:none}#toc-content{padding-bottom:30px;overflow:auto}#toc-content ol{padding-left:10px}#toc-content ol li{padding-left:10px}#toc-content .toc-link:hover{color:#42b983;font-weight:700;text-decoration:underline}#toc-content .toc-link::before{background-color:transparent;max-height:25px;position:absolute;right:23.5vw;display:block}#toc-content .is-active-link{color:#42b983}#floating-toc-btn{position:fixed;right:15px;bottom:76px;padding-top:15px;margin-bottom:0;z-index:998}#floating-toc-btn .btn-floating{width:48px;height:48px}#floating-toc-btn .btn-floating i{line-height:48px;font-size:1.4rem}</style><div class="row"><div id="main-content" class="col s12 m12 l9"><div id="artDetail"><div class="card"><div class="card-content article-info"><div class="row tag-cate"><div class="col s7"><div class="article-tag"><a href="/tags/Scrapy/"><span class="chip bg-color">Scrapy</span> </a><a href="/tags/%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB/"><span class="chip bg-color">网络爬虫</span></a></div></div><div class="col s5 right-align"><div class="post-cate"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/Python/" class="post-category">Python</a></div></div></div><div class="post-info"><div class="post-date info-break-policy"><i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp; 2022-10-03</div><div class="post-date info-break-policy"><i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp; 2022-10-04</div><div class="info-break-policy"><i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp; 5.7k</div><div class="info-break-policy"><i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp; 25 分</div><div id="busuanzi_container_page_pv" class="info-break-policy"><i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp; <span id="busuanzi_value_page_pv"></span></div></div></div><hr class="clearfix"><style type="text/css">code[class*=language-],pre[class*=language-]{white-space:pre-wrap!important}</style><div class="card-content article-card-content"><div id="articleContent"><h3 id="Scrapy-架构"><a href="#Scrapy-架构" class="headerlink" title="Scrapy 架构"></a>Scrapy 架构</h3><p>Scrapy Engine(引擎)： 负责Spider、ItemPipeline、Downloader、Scheduler中间的通讯，信号、数据传递等。<br>Scheduler(调度器)： 它负责接受引擎发送过来的Request请求，并按照一定的方式进行整理排列，入队，当引擎需要时，交还给引擎。<br>Downloader（下载器）： 负责下载Scrapy Engine(引擎)发送的所有Requests请求，并将其获取到的Responses交还给Scrapy Engine(引擎)，由引擎交给Spider来处理。<br>Spider（爬虫）： 它负责处理所有Responses,从中分析提取数据，获取Item字段需要的数据，并将需要跟进的URL提交给引擎，再次进入Scheduler(调度器)。<br>Item Pipeline(管道)： 它负责处理Spider中获取到的Item，并进行进行后期处理（详细分析、过滤、存储等）的地方。<br>Downloader Middlewares（下载中间件）： 一个可以自定义扩展下载功能的组件。<br>Spider Middlewares（Spider中间件）： 一个可以自定扩展和操作引擎和Spider中间通信的功能组件<br><img src="https://cdn.jsdelivr.net/gh/qianchengmoran/images/202210041727676.png"></p><h3 id="Scrapy-原理"><a href="#Scrapy-原理" class="headerlink" title="Scrapy 原理"></a>Scrapy 原理</h3><p>引擎从调度器中取出一个链接（URL）用于接下来的抓取。<br>引擎把URL封装成一个请求（Request）传给下载器。<br>下载器把资源下载下来，并封装成应答包（Response）<br>爬虫解析Response<br>解析出实体（Item），则交给实体管道进行进一步处理<br>解析出的是衔接（URL），则把URL交给调度器等待抓取</p><h3 id="Scrapy-安装"><a href="#Scrapy-安装" class="headerlink" title="Scrapy 安装"></a>Scrapy 安装</h3><ol><li>Windows平台：</li></ol><pre class="line-numbers language-bash"><code class="language-bash">pip3 <span class="token function">install</span> wheel
安装Twisted
进入http://www.lfd.uci.edu/~gohlke/pythonlibs/<span class="token comment" spellcheck="true">#twisted</span>
    根据自身系统环境选择下载。
    比如我的win10 64位 python3.7
    则下载Twisted‑19.10.0‑cp37‑cp37m‑win_amd64.whl
    进入本地下载后的文件夹
    pip3 <span class="token function">install</span> Twisted‑19.10.0‑cp37‑cp37m‑win_amd64.whl
pip3 <span class="token function">install</span> lxml

pip3 <span class="token function">install</span> pyopenssl

pip3 <span class="token function">install</span> pypiwin32

pip3 <span class="token function">install</span> scrapy
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol start="2"><li>Linux平台：</li></ol><pre class="line-numbers language-bash"><code class="language-bash">pip3 <span class="token function">install</span> Scrapy
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>命令行工具<br>成功安装好Scrapy后，在命令行里输入scrapy -h 即可查看帮助</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token comment" spellcheck="true">#1 查看帮助</span>
    scrapy -h
    scrapy <span class="token operator">&lt;</span>command<span class="token operator">></span> -h

<span class="token comment" spellcheck="true">#2 有两种命令：其中Project-only必须切到项目文件夹下才能执行，而Global的命令则不需要</span>
    Global commands:
        startproject <span class="token comment" spellcheck="true">#创建项目</span>
        genspider    <span class="token comment" spellcheck="true">#创建爬虫程序</span>
        settings     <span class="token comment" spellcheck="true">#如果是在项目目录下，则得到的是该项目的配置</span>
        runspider    <span class="token comment" spellcheck="true">#运行一个独立的python文件，不必创建项目</span>
        shell        <span class="token comment" spellcheck="true">#scrapy shell url地址  在交互式调试，如选择器规则正确与否</span>
        fetch        <span class="token comment" spellcheck="true">#独立于程单纯地爬取一个页面，可以拿到请求头</span>
        view         <span class="token comment" spellcheck="true">#下载完毕后直接弹出浏览器，以此可以分辨出哪些数据是ajax请求</span>
        version      <span class="token comment" spellcheck="true">#scrapy version 查看scrapy的版本，scrapy version -v查看scrapy依赖库的版本</span>
    Project-only commands:
        crawl        <span class="token comment" spellcheck="true">#运行爬虫，必须创建项目才行，确保配置文件中ROBOTSTXT_OBEY = False</span>
        check        <span class="token comment" spellcheck="true">#检测项目中有无语法错误</span>
        list         <span class="token comment" spellcheck="true">#列出项目中所包含的爬虫名</span>
        edit         <span class="token comment" spellcheck="true">#编辑器，一般不用</span>
        parse        <span class="token comment" spellcheck="true">#scrapy parse url地址 --callback 回调函数  #以此可以验证我们的回调函数是否正确</span>
        bench        <span class="token comment" spellcheck="true">#scrapy bentch压力测试</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="Scrapy-单页实战案例"><a href="#Scrapy-单页实战案例" class="headerlink" title="Scrapy 单页实战案例"></a>Scrapy 单页实战案例</h3><ol><li>新建爬虫项目<br>新建一个名为 mySpider 的爬虫项目</li></ol><pre class="line-numbers language-bash"><code class="language-bash">scrapy startproject mySpider
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>输入完命令后，在当前目录下会出现一个mySpider的文件夹，目录结构如下</p><pre class="line-numbers language-bash"><code class="language-bash">mySpider/
    scrapy.cfg
    mySpider/
        __init__.py
        items.py
        pipelines.py
        settings.py
        spiders/
            __init__.py
            <span class="token punctuation">..</span>.
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>文件说明：<br>scrapy.cfg 项目的配置信息。主要为Scrapy命令行工具提供一个基础的配置信息。（真正爬虫相关的配置信息在settings.py文件中）<br>mySpider&#x2F; 项目的Python模块，将会从这里引用代码。<br>mySpider&#x2F;items.py 项目的目标文件。设置数据存储模板，用于结构化数据。<br>mySpider&#x2F;pipelines.py 项目的管道文件。数据处理行为，如：一般结构化的数据持久化<br>mySpider&#x2F;settings.py 项目的配置文件，如：递归的层数、并发数，延迟下载等<br>mySpider&#x2F;spiders&#x2F; 爬虫代码目录，如：创建文件，编写爬虫规则<br>2. 明确抓取目标<br>明确目标：爬取<a target="_blank" rel="noopener" href="http://www.itcast.cn/channel/teacher.shtml%E9%A1%B5%E9%9D%A2%E4%B8%AD%E6%89%80%E6%9C%89%E8%AE%B2%E5%B8%88%E7%9A%84%E5%A7%93%E5%90%8D%E3%80%81%E8%81%8C%E7%A7%B0%E5%92%8C%E4%B8%AA%E4%BA%BA%E4%BF%A1%E6%81%AF%E3%80%82">http://www.itcast.cn/channel/teacher.shtml页面中所有讲师的姓名、职称和个人信息。</a><br>打开编写 mySpider 目录下的 items.py。<br>自定义 姓名name、职称title 和 个人信息info 等字段</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> scrapy

<span class="token keyword">class</span> <span class="token class-name">MyspiderItem</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Item<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># define the fields for your item here like:</span>
    name <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
    title <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
    info <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol start="3"><li>制作爬虫代码<br>在 mySpider&#x2F; 目录下输入命令，将会在 mySpider&#x2F;spider 目录下自动生成一个名为 itcast.py 的爬虫文件，并指定爬取域的范围为 itcast.cn ，注意这里的爬虫名不能与项目名称起一样的。</li></ol><pre class="line-numbers language-bash"><code class="language-bash">scrapy genspider itcast <span class="token string">"itcast.cn"</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>打开 mySpider&#x2F;spider 目录里的 itcast.py，自动生成了下列代码:</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> scrapy

<span class="token keyword">class</span> <span class="token class-name">ItcastSpider</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    name <span class="token operator">=</span> <span class="token string">"itcast"</span>
    allowed_domains <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"itcast.cn"</span><span class="token punctuation">]</span>
    start_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'http://www.itcast.cn/'</span><span class="token punctuation">]</span>

    <span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">pass</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>参数介绍：<br>name &#x3D; “” ：这个爬虫的识别名称，必须是唯一的，在不同的爬虫必须定义不同的名字。<br>allow_domains &#x3D; [] 是搜索的域名范围，也就是爬虫的约束区域，规定爬虫只爬取这个域名下的网页，不存在的URL会被忽略。<br>start_urls &#x3D; () ：爬取的URL元祖&#x2F;列表。爬虫从这里开始抓取数据，所以，第一次下载的数据将会从这些urls开始。其他子URL将会从这些起始URL中继承性生成。<br>parse(self, response) ：负责解析返回的网页数据(response.body)，提取结构化数据(生成item)，生成需要下一页的URL请求。<br>导入刚才编写的items.py文件</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> mySpider<span class="token punctuation">.</span>items <span class="token keyword">import</span> MyspiderItem
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>将start_urls的值修改为需要爬取的初始url</p><pre class="line-numbers language-python"><code class="language-python">start_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"http://www.itcast.cn/channel/teacher.shtml"</span><span class="token punctuation">]</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>修改parse()方法，使用XPath语法对返回的response网页数据进行匹配提取</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
    items <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span> 
    <span class="token keyword">for</span> each <span class="token keyword">in</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">"//div[@class='li_txt']"</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment" spellcheck="true"># 循环匹配每个教师的数据</span>
        item <span class="token operator">=</span> MyspiderItem<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 实例化MyspiderItem类</span>
        name <span class="token operator">=</span> each<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">"h3/text()"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 匹配姓名</span>
        title <span class="token operator">=</span> each<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">"h4/text()"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 匹配职称</span>
        info <span class="token operator">=</span> each<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">"p/text()"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 匹配个人信息</span>
        <span class="token comment" spellcheck="true"># 将匹配到的值添加到item中</span>
        item<span class="token punctuation">[</span><span class="token string">'name'</span><span class="token punctuation">]</span> <span class="token operator">=</span> name<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> 
        item<span class="token punctuation">[</span><span class="token string">'title'</span><span class="token punctuation">]</span> <span class="token operator">=</span> title<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
        item<span class="token punctuation">[</span><span class="token string">'info'</span><span class="token punctuation">]</span> <span class="token operator">=</span> info<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
        items<span class="token punctuation">.</span>append<span class="token punctuation">(</span>item<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 将item中的值添加到items</span>
    <span class="token keyword">return</span> items <span class="token comment" spellcheck="true"># 函数返回items</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>Scrapy支持正则语法、CSS语法和XPath语法对网页内容进行匹配，这里推荐使用XPath语法，Scrapy官网也是默认支持使用XPath语法。<br>以上parse()方法用到了XPath语法对指定内容进行匹配，如果有学过CSS，那么这里就非常容易理解XPath语法了。<br>下面将简单对XPath语法举例介绍，更多详细点击查看<a target="_blank" rel="noopener" href="https://www.w3school.com.cn/xpath/index.asp">XPath教程</a><br>首先分析源代码，找到我们所需要的内容<br>先介绍个简单的方法，可以直接在火狐或者谷歌浏览器中，找到相应的位置，鼠标右键-&gt;复制-&gt;XPath可以直接生成XPath语句。<br>复制生成的代码如下</p><pre class="line-numbers language-html"><code class="language-html">/html/body/div[1]/div[5]/div/div[2]/div[13]/ul/li[1]/div[2]
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这样方法生成的XPath语句非常的长，而且不容易理解。</p><p>接下来手动构造的XPath语句进行内容匹配</p><pre class="line-numbers language-html"><code class="language-html"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>div</span> <span class="token attr-name">class</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>li_txt<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>h3</span><span class="token punctuation">></span></span>于老师<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>h3</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>h4</span><span class="token punctuation">></span></span>高级讲师<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>h4</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>p</span><span class="token punctuation">></span></span>Java企业级应用专家、WEB技术专家，中科院软件工程硕士。07年起曾主持研发过多套软件培训课程与教材，精通JAVAEE、PHP、RUBY、JavaSCRIPT、RIA等多种主流开发语言，曾主持参与过中国联通UMMS二期工程等多个大项目。<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>p</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>div</span><span class="token punctuation">></span></span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>现在要匹配class为li_txt的div，构造XPath语句为</p><pre class="line-numbers language-html"><code class="language-html">//div[@class='li_txt']
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>进一步匹配该div下的h3标签的内容，构造XPath语句为</p><pre class="line-numbers language-html"><code class="language-html">//div[@class='li_txt'][1]/h3/text()
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>从以上两个匹配例子可以很清楚的知道我们所要匹配的是什么，其中&#x2F;&#x2F;表示任意的，后接div表示当前页面所有的div，而div后接的[@class&#x3D;’li_txt’]表示指定class为li_txt的div,&#x2F;表示该div紧接下一级内的子标签h3,text()表示当前h3中的文本内容<br>到目前为止，已经成功使用了XPath语法，但是难免保证匹配到的都是正确的结果，所以接下来我们需要验证下我们的XPath是否正确<br>一种办法是使用谷歌浏览器的插件：XPath Helper。需要从谷歌网上应用店下载<br>安装完插件后，点击右上角的X图标即可启动，然后在左边输入框中输入XPath语句，右边实时显示匹配的结果，清晰明了。<br>但此时Scrapy通过response.xpath(语法)不是直接获取字符串，我们需要将其转为字符串格式，通过以下方式可以得到字符串</p><pre class="line-numbers language-python"><code class="language-python">response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 得到一个元素</span>
response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>getall<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 得到多个元素</span>
response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token punctuation">.</span>extract<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>  <span class="token comment" spellcheck="true"># 得到一个元素</span>
response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 得到一个元素</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>另一种方法是通过Scrapy自带的交互式shell来准确验证XPath语句，具体在命令行操作如下,如果能正确print()输出结果，则表示XPath正确。</p><pre class="line-numbers language-bash"><code class="language-bash">zmj@ubuntu:~/桌面$ scrapy shell http://www.itcast.cn/channel/teacher.shtml
2020-03-21 07:04:51 <span class="token punctuation">[</span>scrapy.utils.log<span class="token punctuation">]</span> INFO: Scrapy 2.0.0 started <span class="token punctuation">(</span>bot: scrapybot<span class="token punctuation">)</span>
<span class="token punctuation">..</span><span class="token punctuation">..</span><span class="token punctuation">..</span>
2020-03-21 07:04:51 <span class="token punctuation">[</span>scrapy.core.engine<span class="token punctuation">]</span> INFO: Spider opened
2020-03-21 07:04:51 <span class="token punctuation">[</span>scrapy.core.engine<span class="token punctuation">]</span> DEBUG: Crawled <span class="token punctuation">(</span>200<span class="token punctuation">)</span> <span class="token operator">&lt;</span>GET http://www.itcast.cn/channel/teacher.shtml<span class="token operator">></span> <span class="token punctuation">(</span>referer: None<span class="token punctuation">)</span>
<span class="token punctuation">[</span>s<span class="token punctuation">]</span> Available Scrapy objects:
<span class="token punctuation">[</span>s<span class="token punctuation">]</span>   scrapy     scrapy module <span class="token punctuation">(</span>contains scrapy.Request, scrapy.Selector, etc<span class="token punctuation">)</span>
<span class="token punctuation">[</span>s<span class="token punctuation">]</span>   crawler    <span class="token operator">&lt;</span>scrapy.crawler.Crawler object at 0x7f963e8140d0<span class="token operator">></span>
<span class="token punctuation">[</span>s<span class="token punctuation">]</span>   item       <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;&amp;#125;</span>
<span class="token punctuation">[</span>s<span class="token punctuation">]</span>   request    <span class="token operator">&lt;</span>GET http://www.itcast.cn/channel/teacher.shtml<span class="token operator">></span>
<span class="token punctuation">[</span>s<span class="token punctuation">]</span>   response   <span class="token operator">&lt;</span>200 http://www.itcast.cn/channel/teacher.shtml<span class="token operator">></span>
<span class="token punctuation">[</span>s<span class="token punctuation">]</span>   settings   <span class="token operator">&lt;</span>scrapy.settings.Settings object at 0x7f963e80ff10<span class="token operator">></span>
<span class="token punctuation">[</span>s<span class="token punctuation">]</span>   spider     <span class="token operator">&lt;</span>DefaultSpider <span class="token string">'default'</span> at 0x7f963e369210<span class="token operator">></span>
<span class="token punctuation">[</span>s<span class="token punctuation">]</span> Useful shortcuts:
<span class="token punctuation">[</span>s<span class="token punctuation">]</span>   fetch<span class="token punctuation">(</span>url<span class="token punctuation">[</span>, redirect<span class="token operator">=</span>True<span class="token punctuation">]</span><span class="token punctuation">)</span> Fetch URL and update local objects <span class="token punctuation">(</span>by default, redirects are followed<span class="token punctuation">)</span>
<span class="token punctuation">[</span>s<span class="token punctuation">]</span>   fetch<span class="token punctuation">(</span>req<span class="token punctuation">)</span>                  Fetch a scrapy.Request and update local objects 
<span class="token punctuation">[</span>s<span class="token punctuation">]</span>   shelp<span class="token punctuation">(</span><span class="token punctuation">)</span>           Shell <span class="token function">help</span> <span class="token punctuation">(</span>print this help<span class="token punctuation">)</span>
<span class="token punctuation">[</span>s<span class="token punctuation">]</span>   view<span class="token punctuation">(</span>response<span class="token punctuation">)</span>    View response <span class="token keyword">in</span> a browser
In <span class="token punctuation">[</span>1<span class="token punctuation">]</span>: res <span class="token operator">=</span> response.xpath<span class="token punctuation">(</span><span class="token string">"//div[@class='li_txt']/h3/text()"</span><span class="token punctuation">)</span>

In <span class="token punctuation">[</span>2<span class="token punctuation">]</span>: print<span class="token punctuation">(</span>res<span class="token punctuation">)</span>
<span class="token punctuation">[</span><span class="token operator">&lt;</span>Selector xpath<span class="token operator">=</span><span class="token string">"//div[@class='li_txt']/h3/text()"</span> data<span class="token operator">=</span><span class="token string">'王老师'</span><span class="token operator">></span>,
<span class="token operator">&lt;</span>Selector xpath<span class="token operator">=</span><span class="token string">"//div[@class='li_txt']/h3/text()"</span> data<span class="token operator">=</span><span class="token string">'孙老师'</span><span class="token operator">></span>, 
<span class="token operator">&lt;</span>Selector xpath<span class="token operator">=</span><span class="token string">"//div[@class='li_txt']/h3/text()"</span> data<span class="token operator">=</span><span class="token string">'李老师'</span><span class="token operator">></span>,
<span class="token punctuation">..</span>.<span class="token punctuation">]</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>最后总结 mySpider&#x2F;spider&#x2F;itcast.py 代码如下</p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># -*- coding: utf-8 -*-</span>
<span class="token keyword">import</span> scrapy
<span class="token keyword">from</span> mySpider<span class="token punctuation">.</span>items <span class="token keyword">import</span> MyspiderItem

<span class="token keyword">class</span> <span class="token class-name">ItcastSpider</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    name <span class="token operator">=</span> <span class="token string">'itcast'</span>
    allowed_domains <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'itcast.cn'</span><span class="token punctuation">]</span>
    start_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'http://www.itcast.cn/channel/teacher.shtml'</span><span class="token punctuation">]</span>

    <span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        items <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span> <span class="token comment" spellcheck="true"># 存放老师信息的集合</span>
        <span class="token keyword">for</span> each <span class="token keyword">in</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">"//div[@class='li_txt']"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            item <span class="token operator">=</span> MyspiderItem<span class="token punctuation">(</span><span class="token punctuation">)</span>
            <span class="token comment" spellcheck="true">#extract()方法返回的都是unicode字符串</span>
            name <span class="token operator">=</span> each<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">"h3/text()"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract<span class="token punctuation">(</span><span class="token punctuation">)</span>
            title <span class="token operator">=</span> each<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">"h4/text()"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract<span class="token punctuation">(</span><span class="token punctuation">)</span>
            info <span class="token operator">=</span> each<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">"p/text()"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract<span class="token punctuation">(</span><span class="token punctuation">)</span>
             <span class="token comment" spellcheck="true">#xpath返回的是包含一个元素的列表</span>
            item<span class="token punctuation">[</span><span class="token string">'name'</span><span class="token punctuation">]</span> <span class="token operator">=</span> name<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
            item<span class="token punctuation">[</span><span class="token string">'title'</span><span class="token punctuation">]</span> <span class="token operator">=</span> title<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
            item<span class="token punctuation">[</span><span class="token string">'info'</span><span class="token punctuation">]</span> <span class="token operator">=</span> info<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
            items<span class="token punctuation">.</span>append<span class="token punctuation">(</span>item<span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># 直接返回最后数据</span>
        <span class="token keyword">return</span> items
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol start="4"><li>存储爬取内容<br>首先编辑 mySpider&#x2F; 目录下的 settings.py文件，找到如下代码去除注释。这么做的目的是为了防止某些网站使用了反爬虫策略，进行绕过。</li></ol><pre class="line-numbers language-python"><code class="language-python">ROBOTSTXT_OBEY <span class="token operator">=</span> <span class="token boolean">False</span> <span class="token comment" spellcheck="true"># 是否遵循robotstxt守则，改为False</span>

DEFAULT_REQUEST_HEADERS <span class="token operator">=</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>
   <span class="token string">'Accept'</span><span class="token punctuation">:</span> <span class="token string">'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8'</span><span class="token punctuation">,</span>
   <span class="token string">'Accept-Language'</span><span class="token punctuation">:</span> <span class="token string">'zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2'</span><span class="token punctuation">,</span>
   <span class="token string">'User-Agent'</span><span class="token punctuation">:</span> <span class="token string">'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:74.0) Gecko/20100101 Firefox/74.0'</span><span class="token punctuation">,</span>
<span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;</span>

ITEM_PIPELINES <span class="token operator">=</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>
    <span class="token string">'mySpider.pipelines.MyspiderPipeline'</span><span class="token punctuation">:</span> <span class="token number">300</span><span class="token punctuation">,</span>
<span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>上面的 DEFAULT_REQUEST_HEADERS 中的为请求头中的数据，我们可以在浏览器中-&gt;检查元素-&gt;网络-&gt;刷新加载-&gt;查看请求头 中获取数据<br>Scrapy保存信息的最简单的方法主要有四种，-o 输出指定格式的文件，命令如下</p><pre class="line-numbers language-bash"><code class="language-bash">scrapy crawl itcast -o teachers.json
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>json lines格式，默认为Unicode编码</p><pre class="line-numbers language-bash"><code class="language-bash">scrapy crawl itcast -o teachers.jsonl
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>xml格式</p><pre class="line-numbers language-bash"><code class="language-bash">scrapy crawl itcast -o teachers.xml
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>csv 逗号表达式，可用Excel打开</p><pre class="line-numbers language-bash"><code class="language-bash">scrapy crawl itcast -o teachers.csv
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>注意：当保存成json格式时，并不会直接生成中文<br>为了解决这个问题，我们可以自定义数据保存的格式<br>编辑管道文件 mySpider&#x2F;pipelines.py，默认增加的代码如下</p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># -*- coding: utf-8 -*-</span>

<span class="token keyword">class</span> <span class="token class-name">MyspiderPipeline</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">process_item</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> item<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> item
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>将其修改为如下代码</p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># -*- coding: utf-8 -*-</span>

<span class="token keyword">import</span> json

<span class="token keyword">class</span> <span class="token class-name">MyspiderPipeline</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>filename <span class="token operator">=</span> open<span class="token punctuation">(</span><span class="token string">"teacher.json"</span><span class="token punctuation">,</span><span class="token string">"w"</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">process_item</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> item<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        text <span class="token operator">=</span> json<span class="token punctuation">.</span>dumps<span class="token punctuation">(</span>dict<span class="token punctuation">(</span>item<span class="token punctuation">)</span><span class="token punctuation">,</span>ensure_ascii <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">"\n"</span>
        self<span class="token punctuation">.</span>filename<span class="token punctuation">.</span>write<span class="token punctuation">(</span>str<span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> item

    <span class="token keyword">def</span> <span class="token function">close_spider</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>filename<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>然后回到mySpider&#x2F;目录下，执行运行命令</p><pre class="line-numbers language-bash"><code class="language-bash">scrapy crawl itcast
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>此时成功将存储的json数据变为中文格式</p><h3 id="Scrapy-分页实战案例"><a href="#Scrapy-分页实战案例" class="headerlink" title="Scrapy 分页实战案例"></a>Scrapy 分页实战案例</h3><ol><li>新建爬虫项目<br>新建一个名为 itheimaSpider 的爬虫项目，建议项目名字均以 网站域名+Spider格式命名。</li></ol><pre class="line-numbers language-bash"><code class="language-bash">scrapy startproject itheimaSpider
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="2"><li>明确抓取目标<br>明确目标：爬取<a target="_blank" rel="noopener" href="http://yun.itheima.com/jishu/index/p/1.html%E6%89%80%E6%9C%89%E5%88%86%E9%A1%B5%E4%B8%AD%E7%9A%84%E6%96%87%E7%AB%A0%E6%A0%87%E9%A2%98%E3%80%81%E4%BB%8B%E7%BB%8D%E3%80%81%E9%93%BE%E6%8E%A5%E3%80%81%E6%A0%87%E7%AD%BE%E3%80%81%E6%B5%8F%E8%A7%88%E6%95%B0%E5%92%8C%E6%97%A5%E6%9C%9F%E3%80%82">http://yun.itheima.com/jishu/index/p/1.html所有分页中的文章标题、介绍、链接、标签、浏览数和日期。</a><br>打开编写 itheimaSpider&#x2F; 目录下的 items.py。</li></ol><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> scrapy

<span class="token keyword">class</span> <span class="token class-name">ItheimaspiderItem</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Item<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># define the fields for your item here like:</span>
    itheima_title <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
    itheima_introduce <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
    itheima_url <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
    itheima_tag <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
    itheima_view <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
    itheima_time <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol start="3"><li>制作爬虫代码<br>在 itheimaSpider&#x2F; 目录下输入命令，自动生成 itheima爬虫文件，注意爬虫文件名不要与项目名一样</li></ol><pre class="line-numbers language-bash"><code class="language-bash">scrapy genspider itheima <span class="token string">"itheima.com"</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>编辑 itheimaSpider&#x2F;spider&#x2F;itheima.py 文件<br>从源码分析一下页面跳转链接之间的url的区别<br>从这几个链接很容易可以看出，页面之间的跳转链接是由yun.itheima.com和各a标签中的href属性拼接而成的<br>提取出url相同的部分</p><pre class="line-numbers language-python"><code class="language-python">url <span class="token operator">=</span> <span class="token string">"http://yun.itheima.com"</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>修改置start_urls值</p><pre class="line-numbers language-python"><code class="language-python">start_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'http://yun.itheima.com/jishu/'</span><span class="token punctuation">]</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>导入items模块</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> itheimaSpider<span class="token punctuation">.</span>items <span class="token keyword">import</span> ItheimaspiderItem
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>XPath语法匹配指定内容</p><pre class="line-numbers language-python"><code class="language-python"><span class="token operator">//</span>div<span class="token punctuation">[</span>@<span class="token keyword">class</span><span class="token operator">=</span><span class="token string">'fl'</span><span class="token punctuation">]</span><span class="token operator">/</span>ul<span class="token operator">/</span>li<span class="token operator">/</span>a<span class="token operator">/</span>h2<span class="token operator">/</span>text<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 标题</span>
<span class="token operator">//</span>div<span class="token punctuation">[</span>@<span class="token keyword">class</span><span class="token operator">=</span><span class="token string">'fl'</span><span class="token punctuation">]</span><span class="token operator">/</span>ul<span class="token operator">/</span>li<span class="token operator">/</span>a<span class="token operator">/</span>p<span class="token operator">/</span>text<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 介绍</span>
<span class="token operator">//</span>div<span class="token punctuation">[</span>@<span class="token keyword">class</span><span class="token operator">=</span><span class="token string">'fl'</span><span class="token punctuation">]</span><span class="token operator">/</span>ul<span class="token operator">/</span>li<span class="token operator">/</span>a<span class="token operator">/</span>@href <span class="token comment" spellcheck="true"># 文章链接</span>
<span class="token operator">//</span>div<span class="token punctuation">[</span>@<span class="token keyword">class</span><span class="token operator">=</span><span class="token string">'fl'</span><span class="token punctuation">]</span><span class="token operator">/</span>ul<span class="token operator">/</span>li<span class="token operator">/</span>a<span class="token operator">/</span>div<span class="token operator">/</span>h3<span class="token operator">/</span>text<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 标签</span>
<span class="token operator">//</span>div<span class="token punctuation">[</span>@<span class="token keyword">class</span><span class="token operator">=</span><span class="token string">'fl'</span><span class="token punctuation">]</span><span class="token operator">/</span>ul<span class="token operator">/</span>li<span class="token operator">/</span>a<span class="token operator">/</span>div<span class="token operator">/</span>p<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token operator">/</span>text<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 浏览数</span>
<span class="token operator">//</span>div<span class="token punctuation">[</span>@<span class="token keyword">class</span><span class="token operator">=</span><span class="token string">'fl'</span><span class="token punctuation">]</span><span class="token operator">/</span>ul<span class="token operator">/</span>li<span class="token operator">/</span>a<span class="token operator">/</span>div<span class="token operator">/</span>p<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token operator">/</span>text<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 日期</span>

<span class="token operator">//</span>div<span class="token punctuation">[</span>@<span class="token keyword">class</span><span class="token operator">=</span><span class="token string">'pagebox'</span><span class="token punctuation">]</span><span class="token operator">/</span>div<span class="token operator">/</span>a<span class="token punctuation">[</span>@<span class="token keyword">class</span><span class="token operator">=</span><span class="token string">'next'</span><span class="token punctuation">]</span><span class="token operator">/</span>@href <span class="token comment" spellcheck="true"># 下一页链接</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>提取匹配出每篇文章各自内容的XPath语句部分，作为循环主体</p><pre class="line-numbers language-python"><code class="language-python"><span class="token operator">//</span>div<span class="token punctuation">[</span>@<span class="token keyword">class</span><span class="token operator">=</span><span class="token string">'fl'</span><span class="token punctuation">]</span><span class="token operator">/</span>ul<span class="token operator">/</span>li
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>然后再子循环读取每篇文章下各自的内容</p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 循环读取文章主体</span>
<span class="token keyword">for</span> line <span class="token keyword">in</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">"//div[@class='fl']/ul/li"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># 子循环读取文章内容</span>
    item <span class="token operator">=</span> ItheimaspiderItem<span class="token punctuation">(</span><span class="token punctuation">)</span>
    item<span class="token punctuation">[</span><span class="token string">'itheima_title'</span><span class="token punctuation">]</span> <span class="token operator">=</span> line<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">"./a/h2/text()"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 标题</span>
    item<span class="token punctuation">[</span><span class="token string">'itheima_introduce'</span><span class="token punctuation">]</span> <span class="token operator">=</span> line<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">"./a/p/text()"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 介绍</span>
    item<span class="token punctuation">[</span><span class="token string">'itheima_url'</span><span class="token punctuation">]</span> <span class="token operator">=</span> self<span class="token punctuation">.</span>url <span class="token operator">+</span> line<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">"./a/@href"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 文章链接</span>
    item<span class="token punctuation">[</span><span class="token string">'itheima_tag'</span><span class="token punctuation">]</span> <span class="token operator">=</span> line<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">"./a/div/h3/text()"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 标签</span>
    item<span class="token punctuation">[</span><span class="token string">'itheima_view'</span><span class="token punctuation">]</span> <span class="token operator">=</span> line<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">"./a/div/p[1]/text()"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 浏览数</span>
    item<span class="token punctuation">[</span><span class="token string">'itheima_time'</span><span class="token punctuation">]</span> <span class="token operator">=</span> line<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">"./a/div/p[2]/text()"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 日期</span>
    <span class="token comment" spellcheck="true"># 返回item</span>
    <span class="token keyword">yield</span> item
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>为了能够获取所有分页面的内容，需要自动获取下一页的跳转url，这里使用XPath匹配到下一页a标签的href属性，然后拼接上<a target="_blank" rel="noopener" href="http://yun.itheima.com即可./">http://yun.itheima.com即可。</a></p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 翻页操作</span>
next_page <span class="token operator">=</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">"//div[@class='pagebox']/div/a[@class='next']/@href"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">if</span> next_page<span class="token punctuation">:</span> <span class="token comment" spellcheck="true"># 判断是否有下一页</span>
    <span class="token comment" spellcheck="true"># 拼接下一页的网址</span>
    next_url <span class="token operator">=</span> response<span class="token punctuation">.</span>urljoin<span class="token punctuation">(</span>next_page<span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># 发出Request请求，callback回调parse函数</span>
    <span class="token keyword">yield</span> scrapy<span class="token punctuation">.</span>Request<span class="token punctuation">(</span>next_url<span class="token punctuation">,</span> callback <span class="token operator">=</span> self<span class="token punctuation">.</span>parse<span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>最后总结下 itheimaSpider&#x2F;spiders&#x2F;itheima.py 代码</p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># -*- coding: utf-8 -*-</span>
<span class="token keyword">import</span> scrapy

<span class="token keyword">from</span> itheimaSpider<span class="token punctuation">.</span>items <span class="token keyword">import</span> ItheimaspiderItem

<span class="token keyword">class</span> <span class="token class-name">ItheimaSpider</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    name <span class="token operator">=</span> <span class="token string">'itheima'</span>
    allowed_domains <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'itheima.com'</span><span class="token punctuation">]</span>
    start_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'http://yun.itheima.com/jishu/'</span><span class="token punctuation">]</span>
    url <span class="token operator">=</span> <span class="token string">"http://yun.itheima.com"</span> <span class="token comment" spellcheck="true"># 提取URL相同的部分</span>
    
    <span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment" spellcheck="true"># 循环读取文章主体</span>
        <span class="token keyword">for</span> line <span class="token keyword">in</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">"//div[@class='fl']/ul/li"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token comment" spellcheck="true"># 子循环读取文章内容</span>
            item <span class="token operator">=</span> ItheimaspiderItem<span class="token punctuation">(</span><span class="token punctuation">)</span>
            item<span class="token punctuation">[</span><span class="token string">'itheima_title'</span><span class="token punctuation">]</span> <span class="token operator">=</span> line<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">"./a/h2/text()"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">)</span>
            item<span class="token punctuation">[</span><span class="token string">'itheima_introduce'</span><span class="token punctuation">]</span> <span class="token operator">=</span> line<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">"./a/p/text()"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">)</span>
            item<span class="token punctuation">[</span><span class="token string">'itheima_url'</span><span class="token punctuation">]</span> <span class="token operator">=</span> url <span class="token operator">+</span> line<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">"./a/@href"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">)</span>
            item<span class="token punctuation">[</span><span class="token string">'itheima_tag'</span><span class="token punctuation">]</span> <span class="token operator">=</span> line<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">"./a/div/h3/text()"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">)</span>
            item<span class="token punctuation">[</span><span class="token string">'itheima_view'</span><span class="token punctuation">]</span> <span class="token operator">=</span> line<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">"./a/div/p[1]/text()"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">)</span>
            item<span class="token punctuation">[</span><span class="token string">'itheima_time'</span><span class="token punctuation">]</span> <span class="token operator">=</span> line<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">"./a/div/p[2]/text()"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">)</span>
            <span class="token comment" spellcheck="true"># 返回item</span>
            <span class="token keyword">yield</span> item

        <span class="token comment" spellcheck="true"># 翻页操作</span>
        next_page <span class="token operator">=</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">"//div[@class='pagebox']/div/a[@class='next']/@href"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> next_page<span class="token punctuation">:</span>
            <span class="token comment" spellcheck="true"># 拼接下一页的网址</span>
            next_url <span class="token operator">=</span> response<span class="token punctuation">.</span>urljoin<span class="token punctuation">(</span>next_page<span class="token punctuation">)</span>
            <span class="token comment" spellcheck="true"># 发出Request请求，callback回调parse函数</span>
            <span class="token keyword">yield</span> scrapy<span class="token punctuation">.</span>Request<span class="token punctuation">(</span>next_url<span class="token punctuation">,</span> callback <span class="token operator">=</span> self<span class="token punctuation">.</span>parse<span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol start="4"><li>存储爬取内容<br>编辑 itheimaSpider&#x2F; 目录下的 settings.py 文件，找到如下代码去除注释并修改代码。</li></ol><pre class="line-numbers language-python"><code class="language-python">ROBOTSTXT_OBEY <span class="token operator">=</span> <span class="token boolean">False</span>

DEFAULT_REQUEST_HEADERS <span class="token operator">=</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>
   <span class="token string">'Accept'</span><span class="token punctuation">:</span> <span class="token string">'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8'</span><span class="token punctuation">,</span>
   <span class="token string">'User-Agent'</span><span class="token punctuation">:</span> <span class="token string">'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36'</span>
<span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;</span>

ITEM_PIPELINES <span class="token operator">=</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>
    <span class="token string">'itheimaSpider.pipelines.ItheimaspiderPipeline'</span><span class="token punctuation">:</span> <span class="token number">300</span><span class="token punctuation">,</span>
<span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>最后在 itheimaSpider&#x2F; 输入运行爬虫命令</p><pre class="line-numbers language-bash"><code class="language-bash">scrapy crawl itheima -o itheima.csv
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>保存数据在 itheima.csv 文件中</p><h3 id="Scrapy-爬虫进阶（多级页面）"><a href="#Scrapy-爬虫进阶（多级页面）" class="headerlink" title="Scrapy 爬虫进阶（多级页面）"></a>Scrapy 爬虫进阶（多级页面）</h3><p>演示网站为<a target="_blank" rel="noopener" href="https://www.ivsky.com/bizhi/">https://www.ivsky.com/bizhi/</a> ，目标是爬取该网页中所有图集中的图片<br>本次为三级页面示例，通过一级壁纸首页，找到二级图集首页，再通过图集找到三级图片页面地址，最终目的是要爬取下载所有图集中的图片。<br>一级：<a target="_blank" rel="noopener" href="https://www.ivsky.com/bizhi/">https://www.ivsky.com/bizhi/</a><br>二级：<a target="_blank" rel="noopener" href="https://www.ivsky.com/bizhi/hudie_v58539/">https://www.ivsky.com/bizhi/hudie_v58539/</a><br>三级：<a target="_blank" rel="noopener" href="https://www.ivsky.com/bizhi/hudie_v58539/pic_921157.html">https://www.ivsky.com/bizhi/hudie_v58539/pic_921157.html</a></p><ol><li>新建爬虫项目<br>新建一个名为 ivskySpider 的爬虫项目</li></ol><pre class="line-numbers language-bash"><code class="language-bash">scrapy startproject ivskySpider
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="2"><li>明确抓取目标<br>明确目标：爬取<a target="_blank" rel="noopener" href="https://www.ivsky.com/bizhi/%E6%89%80%E6%9C%89%E5%88%86%E9%A1%B5%E4%B8%AD%E7%9A%84%E5%9B%BE%E7%89%87%E3%80%82">https://www.ivsky.com/bizhi/所有分页中的图片。</a><br>打开编写 ivskySpider&#x2F; 目录下的 items.py。</li></ol><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> scrapy

<span class="token keyword">class</span> <span class="token class-name">ItheimaspiderItem</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Item<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># define the fields for your item here like:</span>
    <span class="token comment" spellcheck="true"># 收集下载图片的url</span>
    image_urls <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># 供给管道下载使用</span>
    images <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol start="3"><li>制作爬虫代码<br>在 ivskySpider&#x2F; 目录下输入命令，自动生成 ivsky爬虫文件,-t crawl表示使用crawl的模板。</li></ol><pre class="line-numbers language-bash"><code class="language-bash">scrapy genspider -t crawl ivsky <span class="token string">"ivsky.com"</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>打开 ivskySpider&#x2F;spider&#x2F;ivsky.py 文件，默认增加的代码如下</p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># -*- coding: utf-8 -*-</span>
<span class="token keyword">import</span> scrapy
<span class="token keyword">from</span> scrapy<span class="token punctuation">.</span>linkextractors <span class="token keyword">import</span> LinkExtractor
<span class="token keyword">from</span> scrapy<span class="token punctuation">.</span>spiders <span class="token keyword">import</span> CrawlSpider<span class="token punctuation">,</span> Rule


<span class="token keyword">class</span> <span class="token class-name">IvskySpider</span><span class="token punctuation">(</span>CrawlSpider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    name <span class="token operator">=</span> <span class="token string">'ivsky'</span>
    allowed_domains <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'ivsky.com'</span><span class="token punctuation">]</span>
    start_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'http://ivsky.com/'</span><span class="token punctuation">]</span>

    rules <span class="token operator">=</span> <span class="token punctuation">(</span>
        Rule<span class="token punctuation">(</span>LinkExtractor<span class="token punctuation">(</span>allow<span class="token operator">=</span>r<span class="token string">'Items/'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> callback<span class="token operator">=</span><span class="token string">'parse_item'</span><span class="token punctuation">,</span> follow<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">parse_item</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        item <span class="token operator">=</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;&amp;#125;</span>
        <span class="token comment" spellcheck="true">#item['domain_id'] = response.xpath('//input[@id="sid"]/@value').get()</span>
        <span class="token comment" spellcheck="true">#item['name'] = response.xpath('//div[@id="name"]').get()</span>
        <span class="token comment" spellcheck="true">#item['description'] = response.xpath('//div[@id="description"]').get()</span>
        <span class="token keyword">return</span> item
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>导入 items.py 文件</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> ivskySpider<span class="token punctuation">.</span>items <span class="token keyword">import</span> IvskyspiderItem
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>修改 start_urls 值如下</p><pre class="line-numbers language-python"><code class="language-python">start_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'https://www.ivsky.com/bizhi/'</span><span class="token punctuation">]</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>先分析一下总共需要获取的url：首页翻页url，图集翻页url，以及图片链接url的格式，进行正则匹配获取，然后编写rules规则匹配</p><pre class="line-numbers language-bash"><code class="language-bash">分析获取url逻辑顺序：
首页 url：www.ivsky.com/bizhi/
  首页翻页：不回调 url：https://www.ivsky.com/bizhi/index_d+.html
    图集首页：不回调 url：https://www.ivsky.com/bizhi/\w+_v\d+/
      图集翻页-》需回调：提取图片url，供下载使用 url：https://www.ivsky.com/bizhi/\w+_v\d+/pic_d+.html

写rule规则时与逻辑顺序相反：
rule图集翻页-》需回调：提取图片url，供下载使用 url：https://www.ivsky.com/bizhi/\w+_v\d+/pic_d+.html
  rule图集首页：不回调 url：https://www.ivsky.com/bizhi/\w+_v\d+/
    rule首页翻页：不回调 url：https://www.ivsky.com/bizhi/index_d+.html
      首页 url：www.ivsky.com/bizhi/
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>修改 rules 规则如下，其中 allow 值中的 \d+ 代表匹配1次或多任意数字值， \w+ 代表匹配1次或多次任意字符值，然后会自动匹配当前页面中所有符合该规则的url格式，更多规则<a target="_blank" rel="noopener" href="https://deerchao.cn/tutorials/regex/regex.htm">点击查看</a></p><pre class="line-numbers language-python"><code class="language-python">rules <span class="token operator">=</span> <span class="token punctuation">(</span>
    Rule<span class="token punctuation">(</span>LinkExtractor<span class="token punctuation">(</span>allow<span class="token operator">=</span>r<span class="token string">'https://www.ivsky.com/bizhi/\w+_v\d+/pic_d+.html'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> callback<span class="token operator">=</span><span class="token string">'parse_item'</span><span class="token punctuation">,</span> follow<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    Rule<span class="token punctuation">(</span>LinkExtractor<span class="token punctuation">(</span>allow<span class="token operator">=</span>r<span class="token string">'https://www.ivsky.com/bizhi/\w+_v\d+/'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> follow<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    Rule<span class="token punctuation">(</span>LinkExtractor<span class="token punctuation">(</span>allow<span class="token operator">=</span>r<span class="token string">'https://www.ivsky.com/bizhi/index_d+.html'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> follow<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span> 
<span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>然后XPath匹配图片下载的链接</p><pre class="line-numbers language-python"><code class="language-python"><span class="token operator">//</span>div<span class="token punctuation">[</span>@id<span class="token operator">=</span><span class="token string">'pic_con'</span><span class="token punctuation">]</span><span class="token operator">/</span>div<span class="token operator">/</span>img<span class="token operator">/</span>@src

response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">"//div[@id='pic_con']/div/img/@src"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>XPath Helper的验证机制出问题。有时候XPath Helper在谷歌浏览器中能正确匹配出想要的内容，但是到了Scrapy中却无法匹配到正确结果。这里强调如果遇到这种情况，建议手动在Scrapy shell中重新使用的XPath语法进行匹配，最后以此为正确结果，具体的情况请看本文结尾的分析。<br>修改 parse_item() 方法如下，主要是将获取的图片url进行list数组返回</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">parse_item</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        item <span class="token operator">=</span> IvskyspiderItem<span class="token punctuation">(</span><span class="token punctuation">)</span>
        image_url <span class="token operator">=</span> <span class="token string">"http:"</span> <span class="token operator">+</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">"//div[@id='pic_con']/div/img/@src"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">)</span>
        image_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        image_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>image_url<span class="token punctuation">)</span>
        item<span class="token punctuation">[</span><span class="token string">'image_urls'</span><span class="token punctuation">]</span> <span class="token operator">=</span> image_list
        <span class="token keyword">yield</span> item
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>最后总结 ivskySpider&#x2F;spider&#x2F;ivsky.py 代码如下</p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># -*- coding: utf-8 -*-</span>
<span class="token keyword">import</span> scrapy
<span class="token keyword">from</span> scrapy<span class="token punctuation">.</span>linkextractors <span class="token keyword">import</span> LinkExtractor
<span class="token keyword">from</span> scrapy<span class="token punctuation">.</span>spiders <span class="token keyword">import</span> CrawlSpider<span class="token punctuation">,</span> Rule
<span class="token keyword">from</span> ivskySpider<span class="token punctuation">.</span>items <span class="token keyword">import</span> IvskyspiderItem
<span class="token keyword">from</span> scrapy<span class="token punctuation">.</span>pipelines<span class="token punctuation">.</span>images <span class="token keyword">import</span> ImagesPipeline

<span class="token keyword">class</span> <span class="token class-name">IvskySpider</span><span class="token punctuation">(</span>CrawlSpider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    name <span class="token operator">=</span> <span class="token string">'ivsky'</span>
    allowed_domains <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'ivsky.com'</span><span class="token punctuation">]</span>
    start_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'https://www.ivsky.com/bizhi/'</span><span class="token punctuation">]</span>

    rules <span class="token operator">=</span> <span class="token punctuation">(</span>
        Rule<span class="token punctuation">(</span>LinkExtractor<span class="token punctuation">(</span>allow<span class="token operator">=</span>r<span class="token string">'https://www.ivsky.com/bizhi/\w+_v\d+/pic_\d+.html'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> callback<span class="token operator">=</span><span class="token string">'parse_item'</span><span class="token punctuation">,</span> follow<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        Rule<span class="token punctuation">(</span>LinkExtractor<span class="token punctuation">(</span>allow<span class="token operator">=</span>r<span class="token string">'https://www.ivsky.com/bizhi/\w+_v\d+/'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> follow<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        Rule<span class="token punctuation">(</span>LinkExtractor<span class="token punctuation">(</span>allow<span class="token operator">=</span>r<span class="token string">'https://www.ivsky.com/bizhi/index_\d+.html'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> follow<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">parse_item</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        item <span class="token operator">=</span> IvskyspiderItem<span class="token punctuation">(</span><span class="token punctuation">)</span>
        image_url <span class="token operator">=</span> <span class="token string">"http:"</span> <span class="token operator">+</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">"//div[@id='pic_con']/div/img/@src"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">)</span>
        image_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        image_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>image_url<span class="token punctuation">)</span>
        item<span class="token punctuation">[</span><span class="token string">'image_urls'</span><span class="token punctuation">]</span> <span class="token operator">=</span> image_list

        <span class="token keyword">yield</span> item
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol start="4"><li>存储爬取内容<br>编辑 ivskySpider&#x2F; 目录下的 settings.py 文件，找到如下代码去除注释并修改代码。</li></ol><pre class="line-numbers language-python"><code class="language-python">ROBOTSTXT_OBEY <span class="token operator">=</span> <span class="token boolean">False</span>

DEFAULT_REQUEST_HEADERS <span class="token operator">=</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>
   <span class="token string">'Accept'</span><span class="token punctuation">:</span> <span class="token string">'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8'</span><span class="token punctuation">,</span>
   <span class="token string">'User-Agent'</span><span class="token punctuation">:</span> <span class="token string">'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36'</span><span class="token punctuation">,</span>
   <span class="token string">'Referer'</span><span class="token punctuation">:</span> <span class="token string">'https://www.ivsky.com'</span><span class="token punctuation">,</span> <span class="token comment" spellcheck="true"># 防止网站防跨域</span>
<span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;</span>

ITEM_PIPELINES <span class="token operator">=</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>
    <span class="token string">'scrapy.pipelines.images.ImagesPipeline'</span><span class="token punctuation">:</span> <span class="token number">300</span><span class="token punctuation">,</span> <span class="token comment" spellcheck="true"># 开启图片下载管道</span>
<span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;</span>

<span class="token comment" spellcheck="true"># 添加代码设置下载路径</span>
IMAGES_STORE <span class="token operator">=</span> <span class="token string">'img'</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>最后在 ivskySpider&#x2F; 输入运行爬虫命令</p><pre class="line-numbers language-bash"><code class="language-bash">scrapy crawl ivsky
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>保存数据在 ivskySpider&#x2F;img&#x2F;full 目录下</p><h3 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h3><p>这里着重提示真正的XPath语句以Scrapy shell中的语句为准，在其他的XPath插件中的语句仅供参考。<br>例如下面这种情况：两个XPath语句目的是为了匹配出图片的链接地址<br>首先是这句XPath，使用谷歌的XPath Helper插件匹配是正确的，没有问题</p><pre class="line-numbers language-python"><code class="language-python"><span class="token operator">//</span>a<span class="token punctuation">[</span>@<span class="token keyword">class</span><span class="token operator">=</span><span class="token string">'page-next'</span><span class="token punctuation">]</span><span class="token operator">/</span>img<span class="token operator">/</span>@src
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>但是同样的这句话，到了Scrapy shell中却失效了，没有匹配到任何信息</p><pre class="line-numbers language-bash"><code class="language-bash">zmj@ubuntu:~/桌面$ scrapy shell https://www.ivsky.com/bizhi/hudie_v58539/pic_921157.html
<span class="token punctuation">..</span><span class="token punctuation">..</span><span class="token punctuation">..</span>
2020-03-21 05:10:15 <span class="token punctuation">[</span>scrapy.core.engine<span class="token punctuation">]</span> DEBUG: Crawled <span class="token punctuation">(</span>200<span class="token punctuation">)</span> <span class="token operator">&lt;</span>GET https://www.ivsky.com/bizhi/hudie_v58539/pic_921157.html<span class="token operator">></span> <span class="token punctuation">(</span>referer: None<span class="token punctuation">)</span>
<span class="token punctuation">[</span>s<span class="token punctuation">]</span> Available Scrapy objects:
<span class="token punctuation">[</span>s<span class="token punctuation">]</span>   scrapy     scrapy module <span class="token punctuation">(</span>contains scrapy.Request, scrapy.Selector, etc<span class="token punctuation">)</span>
<span class="token punctuation">[</span>s<span class="token punctuation">]</span>   crawler    <span class="token operator">&lt;</span>scrapy.crawler.Crawler object at 0x7fead038d610<span class="token operator">></span>
<span class="token punctuation">[</span>s<span class="token punctuation">]</span>   item       <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;&amp;#125;</span>
<span class="token punctuation">[</span>s<span class="token punctuation">]</span>   request    <span class="token operator">&lt;</span>GET https://www.ivsky.com/bizhi/hudie_v58539/pic_921157.html<span class="token operator">></span>
<span class="token punctuation">[</span>s<span class="token punctuation">]</span>   response   <span class="token operator">&lt;</span>200 https://www.ivsky.com/bizhi/hudie_v58539/pic_921157.html<span class="token operator">></span>
<span class="token punctuation">[</span>s<span class="token punctuation">]</span>   settings   <span class="token operator">&lt;</span>scrapy.settings.Settings object at 0x7fead038d210<span class="token operator">></span>
<span class="token punctuation">[</span>s<span class="token punctuation">]</span>   spider     <span class="token operator">&lt;</span>DefaultSpider <span class="token string">'default'</span> at 0x7feacfee26d0<span class="token operator">></span>
<span class="token punctuation">[</span>s<span class="token punctuation">]</span> Useful shortcuts:
<span class="token punctuation">[</span>s<span class="token punctuation">]</span>   fetch<span class="token punctuation">(</span>url<span class="token punctuation">[</span>, redirect<span class="token operator">=</span>True<span class="token punctuation">]</span><span class="token punctuation">)</span> Fetch URL and update local objects <span class="token punctuation">(</span>by default, redirects are followed<span class="token punctuation">)</span>
<span class="token punctuation">[</span>s<span class="token punctuation">]</span>   fetch<span class="token punctuation">(</span>req<span class="token punctuation">)</span>                  Fetch a scrapy.Request and update local objects 
<span class="token punctuation">[</span>s<span class="token punctuation">]</span>   shelp<span class="token punctuation">(</span><span class="token punctuation">)</span>           Shell <span class="token function">help</span> <span class="token punctuation">(</span>print this help<span class="token punctuation">)</span>
<span class="token punctuation">[</span>s<span class="token punctuation">]</span>   view<span class="token punctuation">(</span>response<span class="token punctuation">)</span>    View response <span class="token keyword">in</span> a browser
In <span class="token punctuation">[</span>1<span class="token punctuation">]</span>: url <span class="token operator">=</span> response.xpath<span class="token punctuation">(</span><span class="token string">"//a[@class='page-next']/img/@src"</span><span class="token punctuation">)</span>.get<span class="token punctuation">(</span><span class="token punctuation">)</span>

In <span class="token punctuation">[</span>2<span class="token punctuation">]</span>: print<span class="token punctuation">(</span>url<span class="token punctuation">)</span>
None

In <span class="token punctuation">[</span>3<span class="token punctuation">]</span>:
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>既然scrapy不认这句XPath，那么只好在scrapy shell重新手动匹配</p><pre class="line-numbers language-bash"><code class="language-bash">In <span class="token punctuation">[</span>3<span class="token punctuation">]</span>: url <span class="token operator">=</span> response.xpath<span class="token punctuation">(</span><span class="token string">"//div[@id='pic_con']"</span><span class="token punctuation">)</span>.get<span class="token punctuation">(</span><span class="token punctuation">)</span>

In <span class="token punctuation">[</span>4<span class="token punctuation">]</span>: print<span class="token punctuation">(</span>url<span class="token punctuation">)</span>
<span class="token operator">&lt;</span>div id<span class="token operator">=</span><span class="token string">"pic_con"</span><span class="token operator">></span><span class="token operator">&lt;</span>div<span class="token operator">></span><span class="token operator">&lt;</span>script<span class="token operator">></span>dy<span class="token punctuation">(</span><span class="token string">"pic_tonext"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token operator">&lt;</span>/script<span class="token operator">></span><span class="token operator">&lt;</span>img id<span class="token operator">=</span><span class="token string">"imgis"</span> src<span class="token operator">=</span><span class="token string">"//img.ivsky.com/img/bizhi/pre/201910/07/hudie.jpg"</span> alt<span class="token operator">=</span><span class="token string">"美丽可爱的蝴蝶图片"</span><span class="token operator">></span><span class="token operator">&lt;</span>/div<span class="token operator">></span><span class="token operator">&lt;</span>/div<span class="token operator">></span>

In <span class="token punctuation">[</span>5<span class="token punctuation">]</span>: url <span class="token operator">=</span> response.xpath<span class="token punctuation">(</span><span class="token string">"//div[@id='pic_con']/div/img/@src"</span><span class="token punctuation">)</span>.get<span class="token punctuation">(</span><span class="token punctuation">)</span>

In <span class="token punctuation">[</span>6<span class="token punctuation">]</span>: print<span class="token punctuation">(</span>url<span class="token punctuation">)</span>
//img.ivsky.com/img/bizhi/pre/201910/07/hudie.jpg

In <span class="token punctuation">[</span>7<span class="token punctuation">]</span>:
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>最后匹配到的真正url的XPath语句为</p><pre class="line-numbers language-bash"><code class="language-bash">//div<span class="token punctuation">[</span>@id<span class="token operator">=</span><span class="token string">'pic_con'</span><span class="token punctuation">]</span>/div/img/@src

response.xpath<span class="token punctuation">(</span><span class="token string">"//div[@id='pic_con']/div/img/@src"</span><span class="token punctuation">)</span>.get<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>同样的再将scrapy shell匹配出的这句XPath放到谷歌浏览器中也没法匹配到url</p><p>造成这个原因是使用Scrapy在爬取目标网站时与在浏览器访问目标网站时的源码有些差距。</p><h3 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h3><p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/jiangzijiang/p/8459669.html">https://www.cnblogs.com/jiangzijiang/p/8459669.html</a><br><a target="_blank" rel="noopener" href="https://wwhttps//www.cnblogs.com/kermitjam/p/11117775.html">https://wwhttps://www.cnblogs.com/kermitjam/p/11117775.html</a></p></div><hr><div class="reprint" id="reprint-statement"><div class="reprint__author"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-user">文章作者: </i></span><span class="reprint-info"><a href="/about" rel="external nofollow noreferrer">QianCheng</a></span></div><div class="reprint__type"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-link">文章链接: </i></span><span class="reprint-info"><a href="http://qianchengmoran.github.io/undefined/50470.html">http://qianchengmoran.github.io/undefined/50470.html</a></span></div><div class="reprint__notice"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-copyright">版权声明: </i></span><span class="reprint-info">本博客所有文章除特別声明外，均采用 <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a> 许可协议。转载请注明来源 <a href="/about" target="_blank">QianCheng</a> !</span></div></div><script async defer>document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }</script><div class="tag_share" style="display:block"><div class="post-meta__tag-list" style="display:inline-block"><div class="article-tag"><a href="/tags/Scrapy/"><span class="chip bg-color">Scrapy</span> </a><a href="/tags/%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB/"><span class="chip bg-color">网络爬虫</span></a></div></div><div class="post_share" style="zoom:80%;width:fit-content;display:inline-block;float:right;margin:-.15rem 0"><link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css"><div id="article-share"></div></div></div><style>#reward{margin:40px 0;text-align:center}#reward .reward-link{font-size:1.4rem;line-height:38px}#reward .btn-floating:hover{box-shadow:0 6px 12px rgba(0,0,0,.2),0 5px 15px rgba(0,0,0,.2)}#rewardModal{width:320px;height:350px}#rewardModal .reward-title{margin:15px auto;padding-bottom:5px}#rewardModal .modal-content{padding:10px}#rewardModal .close{position:absolute;right:15px;top:15px;color:rgba(0,0,0,.5);font-size:1.3rem;line-height:20px;cursor:pointer}#rewardModal .close:hover{color:#ef5350;transform:scale(1.3);-moz-transform:scale(1.3);-webkit-transform:scale(1.3);-o-transform:scale(1.3)}#rewardModal .reward-tabs{margin:0 auto;width:210px}.reward-tabs .tabs{height:38px;margin:10px auto;padding-left:0}.reward-content ul{padding-left:0!important}.reward-tabs .tabs .tab{height:38px;line-height:38px}.reward-tabs .tab a{color:#fff;background-color:#ccc}.reward-tabs .tab a:hover{background-color:#ccc;color:#fff}.reward-tabs .wechat-tab .active{color:#fff!important;background-color:#22ab38!important}.reward-tabs .alipay-tab .active{color:#fff!important;background-color:#019fe8!important}.reward-tabs .reward-img{width:210px;height:210px}</style><div id="reward"><a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a><div id="rewardModal" class="modal"><div class="modal-content"><a class="close modal-close"><i class="fas fa-times"></i></a><h4 class="reward-title">你的赏识是我前进的动力</h4><div class="reward-content"><div class="reward-tabs"><ul class="tabs row"><li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li><li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li></ul><div id="alipay"><img src="/medias/reward/alipay.jpg" class="reward-img" alt="支付宝打赏二维码"></div><div id="wechat"><img src="/medias/reward/wechat.png" class="reward-img" alt="微信打赏二维码"></div></div></div></div></div></div><script>$(function(){$(".tabs").tabs()})</script></div></div><div class="livere-card card" data-aos="fade-up"><div id="lv-container" class="card-content" data-id="city" data-uid="MTAyMC81NzM2MS8zMzgyNQ=="><script type="text/javascript">(function (d, s) {
                let j, e = d.getElementsByTagName(s)[0];
                if (typeof LivereTower === 'function') {
                    return;
                }

                j = d.createElement(s);
                j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
                j.async = true;

                e.parentNode.insertBefore(j, e);
            })(document, 'script');</script><noscript>为正常使用来必力评论功能请激活JavaScript。</noscript></div></div><article id="prenext-posts" class="prev-next articles"><div class="row article-row"><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge left-badge text-color"><i class="fas fa-chevron-left"></i>&nbsp;上一篇</div><div class="card"><a href="/undefined/60025.html"><div class="card-image"><img src="/medias/featureimages/15.jpg" class="responsive-img" alt="SwitchHosts加速GitHub修改Hosts"> <span class="card-title">SwitchHosts加速GitHub修改Hosts</span></div></a><div class="card-content article-content"><div class="summary block-with-text">修改系统Hosts文件,加速GitHub仓库</div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2022-10-26 </span><span class="publish-author"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/Github/" class="post-category">Github</a></span></div></div><div class="card-action article-tags"><a href="/tags/github/"><span class="chip bg-color">github</span> </a><a href="/tags/SwitchHosts/"><span class="chip bg-color">SwitchHosts</span></a></div></div></div><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge right-badge text-color">下一篇&nbsp;<i class="fas fa-chevron-right"></i></div><div class="card"><a href="/undefined/56414.html"><div class="card-image"><img src="/medias/featureimages/4.jpg" class="responsive-img" alt="Linux入门简介教程"> <span class="card-title">Linux入门简介教程</span></div></a><div class="card-content article-content"><div class="summary block-with-text">Linux是一个基于POSIX和Unix的多用户、多任务、支持多线程和多CPU的性能稳定的操作系统，Linux操作系统最初由一位名为Linus Torvalds（林纳斯 托瓦兹）的芬兰赫尔辛基大学的学生编制内核，随后由全世界各地的成千上万的程序员设计和实现</div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2022-10-02 </span><span class="publish-author"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/Linux/" class="post-category">Linux</a></span></div></div><div class="card-action article-tags"><a href="/tags/Linux/"><span class="chip bg-color">Linux</span> </a><a href="/tags/%E7%B3%BB%E7%BB%9F/"><span class="chip bg-color">系统</span></a></div></div></div></div></article></div><script>$("#articleContent").on("copy",function(e){var n,t,o,i;void 0!==window.getSelection&&((""+(n=window.getSelection())).length<Number.parseInt("120")||(t=document.getElementsByTagName("body")[0],(o=document.createElement("div")).style.position="absolute",o.style.left="-99999px",t.appendChild(o),o.appendChild(n.getRangeAt(0).cloneContents()),"CODE"===n.getRangeAt(0).commonAncestorContainer.nodeName&&(o.innerHTML="<pre>"+o.innerHTML+"</pre>"),i=document.location.href,o.innerHTML+='<br />来源: 千城墨染<br />文章作者: QianCheng<br />文章链接: <a href="'+i+'">'+i+"</a><br />本文章著作权归作者所有，任何形式的转载都请注明出处。",n.selectAllChildren(o),window.setTimeout(function(){t.removeChild(o)},200)))})</script><script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script><script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script><script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script><script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script></div><div id="toc-aside" class="expanded col l3 hide-on-med-and-down"><div class="toc-widget card" style="background-color:#fff"><div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div><div id="toc-content"></div></div></div></div><div id="floating-toc-btn" class="hide-on-med-and-down"><a class="btn-floating btn-large bg-color"><i class="fas fa-list-ul"></i></a></div><script src="/libs/tocbot/tocbot.min.js"></script><script>$(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });</script></main><footer class="page-footer bg-color"><link rel="stylesheet" href="/libs/aplayer/APlayer.min.css"><style>.aplayer .aplayer-lrc p{display:none;font-size:12px;font-weight:700;line-height:16px!important}.aplayer .aplayer-lrc p.aplayer-lrc-current{display:none;font-size:15px;color:#42b983}.aplayer.aplayer-fixed.aplayer-narrow .aplayer-body{left:-66px!important}.aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover{left:0!important}</style><div><div class="row"><meting-js class="col l8 offset-l2 m10 offset-m1 s12" server="tencent" type="playlist" id="8571951905" fixed="true" autoplay theme="#42b983" loop order="random" preload="auto" volume="0.7" list-folded="true"></meting-js></div></div><script src="/libs/aplayer/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/npm/meting@2/dist/Meting.min.js"></script><div class="container row center-align" style="margin-bottom:15px!important"><div class="col s12 m8 l8 copy-right">&copy;<span id="year">2020</span>-<span id="year">2021</span>&nbsp;<i id="heartbeat" class="fa fas fa-heartbeat"></i>&nbsp; <a href="/about" target="_blank">QianCheng</a><br>快乐每一天！<br>&nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span class="white-color">26.9k</span>&nbsp;字 <span id="busuanzi_container_site_pv">|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;<span id="busuanzi_value_site_pv" class="white-color"></span>&nbsp;次 </span><span id="busuanzi_container_site_uv">|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;<span id="busuanzi_value_site_uv" class="white-color"></span>&nbsp;人</span><br><span id="sitetime">载入运行时间...</span><script>function siteTime(){var e=36e5,t=24*e,n=new Date,o="2020",r=n.getFullYear(),a=n.getMonth()+1,i=n.getDate(),l=n.getHours(),m=n.getMinutes(),M=n.getSeconds(),g=Date.UTC(o,"6","28","0","0","0"),d=Date.UTC(r,a,i,l,m,M)-g,s=Math.floor(d/31536e6),u=Math.floor(d/t-365*s),T=Math.floor((d-(365*s+u)*t)/e),c=Math.floor((d-(365*s+u)*t-T*e)/6e4),f=Math.floor((d-(365*s+u)*t-T*e-6e4*c)/1e3);o==r?(document.getElementById("year").innerHTML=r,document.getElementById("sitetime").innerHTML="本站已安全运行 "+u+" 天 "+T+" 小时 "+c+" 分钟 "+f+" 秒"):(document.getElementById("year").innerHTML=o+" - "+r,document.getElementById("sitetime").innerHTML="本站已安全运行 "+s+" 年 "+u+" 天 "+T+" 小时 "+c+" 分钟 "+f+" 秒")}setInterval(siteTime,1e3)</script><br></div><div class="col s12 m4 l4 social-link social-statis"><a href="mailto:qchmr783589092@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50"><i class="fas fa-envelope-open"></i> </a><a href="/atom.xml" class="tooltipped" target="_blank" data-tooltip="RSS 订阅" data-position="top" data-delay="50"><i class="fas fa-rss"></i></a></div></div></footer><div class="progress-bar"></div><div id="searchModal" class="modal"><div class="modal-content"><div class="search-header"><span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span> <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字" class="search-input"></div><div id="searchResult"></div></div></div><script type="text/javascript">$(function(){!function(t,s,i){"use strict";$.ajax({url:t,dataType:"xml",success:function(t){var e=$("entry",t).map(function(){return{title:$("title",this).text(),content:$("content",this).text(),url:$("url",this).text()}}).get(),n=document.getElementById(s),r=document.getElementById(i);n.addEventListener("input",function(){var f='<ul class="search-result-list">',m=this.value.trim().toLowerCase().split(/[\s\-]+/);r.innerHTML="",this.value.trim().length<=0||(e.forEach(function(t){var n,e,r,s,i,l=!0,a=t.title.trim().toLowerCase(),c=t.content.trim().replace(/<[^>]+>/g,"").toLowerCase(),u=0===(u=t.url).indexOf("/")?t.url:"/"+u,o=-1,h=-1;""!==a&&""!==c&&m.forEach(function(t,e){n=a.indexOf(t),o=c.indexOf(t),n<0&&o<0?l=!1:(o<0&&(o=0),0===e&&(h=o))}),l&&(f+="<li><a href='"+u+"' class='search-result-title'>"+a+"</a>",e=t.content.trim().replace(/<[^>]+>/g,""),0<=h&&(s=h+80,(r=h-20)<0&&(r=0),0===r&&(s=100),s>e.length&&(s=e.length),i=e.substr(r,s),m.forEach(function(t){var e=new RegExp(t,"gi");i=i.replace(e,'<em class="search-keyword">'+t+"</em>")}),f+='<p class="search-result">'+i+"...</p>"),f+="</li>")}),f+="</ul>",r.innerHTML=f)})}})}("/search.xml","searchInput","searchResult")})</script><div id="backTop" class="top-scroll"><a class="btn-floating btn-large waves-effect waves-light" href="#!"><i class="fas fa-arrow-up"></i></a></div><div class="sum-moon-box"><a class="btn-floating btn-large waves-effect waves-light" onclick="switchNightMode()" title="切换主题"><i id="sum-moon-icon" class="fas fa-sun" style="width:48px;height:48px;font-size:28px"></i></a></div><script>function switchNightMode(){$('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($("body")),setTimeout(function(){$("body").hasClass("DarkMode")?($("body").removeClass("DarkMode"),localStorage.setItem("isDark","0"),$("#sum-moon-icon").removeClass("fa-sun").addClass("fa-moon")):($("body").addClass("DarkMode"),localStorage.setItem("isDark","1"),$("#sum-moon-icon").addClass("fa-sun").removeClass("fa-moon")),setTimeout(function(){$(".Cuteen_DarkSky").fadeOut(1e3,function(){$(this).remove()})},2e3)})}</script><div class="stars-con"><div id="stars"></div><div id="stars2"></div><div id="stars3"></div></div><script>"1"===localStorage.getItem("isDark")?(document.body.classList.add("DarkMode"),$("#sum-moon-icon").addClass("fa-sun").removeClass("fa-moon")):(document.body.classList.remove("DarkMode"),$("#sum-moon-icon").removeleClass("fa-sun").addClass("fa-moon"))</script><script src="/libs/materialize/materialize.min.js"></script><script src="/libs/masonry/masonry.pkgd.min.js"></script><script src="/libs/aos/aos.js"></script><script src="/libs/scrollprogress/scrollProgress.min.js"></script><script src="/libs/lightGallery/js/lightgallery-all.min.js"></script><script src="/js/matery.js"></script><script>!function(){var t=document.createElement("script"),e=window.location.protocol.split(":")[0];t.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(t,s)}()</script><script src="/libs/others/clicklove.js" async></script><script async src="/libs/others/busuanzi.pure.mini.js"></script><script type="text/javascript" color="0,0,255" pointcolor="0,0,255" opacity="0.7" zindex="-1" count="99" src="/libs/background/canvas-nest.js"></script><script type="text/javascript" src="/libs/background/ribbon-dynamic.js" async></script><script src="/libs/instantpage/instantpage.js" type="module"></script><script src="//cdn.jsdelivr.net/npm/js-base64/base64.min.js"></script><script>const hasAttr = (e,a) => a.some(_=> e.attr(_)!==undefined);
        $('a').each(function() {
          const $this = $(this);
          if(hasAttr($this,["data-fancybox","ignore-external-link"])) return;
          const href = $this.attr('href');
          if (href && href.match('^((http|https|thunder|qqdl|ed2k|Flashget|qbrowser|ftp|rtsp|mms)://)')) {
            const strs = href.split('/');
            if (strs.length >= 3) {
                const host = strs[2];
                if (host !== 'qianchengmoran.github.io' || window.location.host) {
                    $this.attr('href', '/go.html?u='+Base64.encode(href)+'').attr('rel', 'external nofollow noopener noreferrer');
                    if (true) {
                        $this.attr('target', '_blank');
                    }
                }
            }
          }
        });</script></body></html><script type="text/javascript">var windowWidth=$(window).width();768<windowWidth&&document.write('<script type="text/javascript" src="/js/sakura.js"><\/script>')</script><script type="text/javascript">window.$crisp=[],window.CRISP_WEBSITE_ID="e53512a1-dd24-4765-82a9-8f2052f1ec16",d=document,s=d.createElement("script"),s.src="https://client.crisp.chat/l.js",s.async=1,d.getElementsByTagName("head")[0].appendChild(s)</script><script type="text/javascript">window.onload=function(){document.onkeydown=function(){var e=window.event||arguments[0];return 123!=e.keyCode&&((!e.ctrlKey||!e.shiftKey||73!=e.keyCode)&&((!e.shiftKey||121!=e.keyCode)&&((!e.ctrlKey||85!=e.keyCode)&&void 0)))},document.oncontextmenu=function(){return!1}}</script>